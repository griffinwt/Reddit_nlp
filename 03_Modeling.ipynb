{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Modeling  \n",
    "\n",
    "(introduction here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip Ahead:  \n",
    "\n",
    "[Model 1](#Model-1)  \n",
    "[Model 2](#Model-2)  \n",
    "[Model 3](#Model-3)  \n",
    "[Model 4](#Model-4)  \n",
    "[Model 5](#Model-5)  \n",
    "[Significant Words](#Significant-Words)  \n",
    "[Model 6](#Model-6)  \n",
    "[Coefficient Considerations](#Coefficient-Considerations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "#common code:\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "#week 3\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "#week 4\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "#week 5\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sub_data/clean_subs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jc3ty3</td>\n",
       "      <td>jaaytf_</td>\n",
       "      <td>2</td>\n",
       "      <td>hey so my xbox one is turning on and instantly...</td>\n",
       "      <td>xbox one problems:)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/xbox/comments/jc3ty3/...</td>\n",
       "      <td>xbox one problems:) hey so my xbox one is turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>jc3tg4</td>\n",
       "      <td>Matty_Rts</td>\n",
       "      <td>0</td>\n",
       "      <td>For context, I purchased game pass on Xbox One...</td>\n",
       "      <td>My Preorder download for Beyond Light Disappea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/xbox/comments/jc3tg4/...</td>\n",
       "      <td>My Preorder download for Beyond Light Disappea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>jc39t3</td>\n",
       "      <td>Rorydo44</td>\n",
       "      <td>2</td>\n",
       "      <td>I had $50 worth of gift cards in my account an...</td>\n",
       "      <td>Missing gift cards</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/xbox/comments/jc39t3/...</td>\n",
       "      <td>Missing gift cards I had $50 worth of gift car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>jc37vv</td>\n",
       "      <td>NonsenseText</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi everyone! \\n\\nI would like to learn more ab...</td>\n",
       "      <td>Advice for Xbox online security?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/xbox/comments/jc37vv/...</td>\n",
       "      <td>Advice for Xbox online security? Hi everyone! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>jc36eg</td>\n",
       "      <td>Mondo-Butter-21</td>\n",
       "      <td>4</td>\n",
       "      <td>Srsly tho, how tf did Doom Eternal get onto th...</td>\n",
       "      <td>Anyone else think it’s fucking hilarious that ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/xbox/comments/jc36eg/...</td>\n",
       "      <td>Anyone else think it’s fucking hilarious that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit      id           author  num_comments  \\\n",
       "0          0  jc3ty3          jaaytf_             2   \n",
       "1          0  jc3tg4        Matty_Rts             0   \n",
       "2          0  jc39t3         Rorydo44             2   \n",
       "3          0  jc37vv     NonsenseText             0   \n",
       "4          0  jc36eg  Mondo-Butter-21             4   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  hey so my xbox one is turning on and instantly...   \n",
       "1  For context, I purchased game pass on Xbox One...   \n",
       "2  I had $50 worth of gift cards in my account an...   \n",
       "3  Hi everyone! \\n\\nI would like to learn more ab...   \n",
       "4  Srsly tho, how tf did Doom Eternal get onto th...   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0                                xbox one problems:)           1.0   \n",
       "1  My Preorder download for Beyond Light Disappea...           1.0   \n",
       "2                                 Missing gift cards           1.0   \n",
       "3                   Advice for Xbox online security?           1.0   \n",
       "4  Anyone else think it’s fucking hilarious that ...           1.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/xbox/comments/jc3ty3/...   \n",
       "1  https://www.reddit.com/r/xbox/comments/jc3tg4/...   \n",
       "2  https://www.reddit.com/r/xbox/comments/jc39t3/...   \n",
       "3  https://www.reddit.com/r/xbox/comments/jc37vv/...   \n",
       "4  https://www.reddit.com/r/xbox/comments/jc36eg/...   \n",
       "\n",
       "                                            all_text  \n",
       "0  xbox one problems:) hey so my xbox one is turn...  \n",
       "1  My Preorder download for Beyond Light Disappea...  \n",
       "2  Missing gift cards I had $50 worth of gift car...  \n",
       "3  Advice for Xbox online security? Hi everyone! ...  \n",
       "4  Anyone else think it’s fucking hilarious that ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#referring to lesson 5.05 lecture notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['all_text']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.50237\n",
       "0    0.49763\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like my distribution between the subreddits after cleaning is very close to 50/50, which is good! As a reminder, 1 is for Playstation and 0 is for Xbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500102\n",
       "0    0.499898\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.509172\n",
       "0    0.490828\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay - it looks like my train and test data distribution reflects my true y distribution very well. Excellent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start by CountVectorizing the data and then a Naive Bayes model. The easiest way to accomplish both will be performing them concurrently using a pipeline. I will probably want to try the Term Frequency-Inverse Document Frequency (TF-IDF) Vectorizer as well so I'm going to build a pipeline making function that can handle either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipemaker(scaler, classifier):\n",
    "    if scaler == 'cvec':\n",
    "        item1 = ('cvec', CountVectorizer())\n",
    "    elif scaler == 'tvec':\n",
    "        item1 = ('tvec', TfidfVectorizer())\n",
    "    else:\n",
    "        return 'Error. Please enter \"cvec\" or \"tvec\"'\n",
    "    if classifier == 'nb':\n",
    "        item2 = ('nb', MultinomialNB())\n",
    "    else:\n",
    "        return 'Error. Please enter \"nb\"'\n",
    "    return Pipeline([item1, item2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cvec', CountVectorizer()), ('nb', MultinomialNB())])\n"
     ]
    }
   ],
   "source": [
    "pipe = pipemaker('cvec', 'nb') #test\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just picking one set of paramaters and proceeding, I'm going to pause here and write a reusable function to set paramaters so that as I tweak my model, it will be easy to update the parameters and run the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(scaler, max_feat_list, min_df_list, max_df_list, ngram_list):\n",
    "    if scaler != 'cvec' and scaler != 'tvec':\n",
    "        return 'Please enter either cvec or tvec as the first item.'\n",
    "    pipe_params = {f'{scaler}__max_features': max_feat_list,\n",
    "              f'{scaler}__min_df': min_df_list,\n",
    "              f'{scaler}__max_df': max_df_list,\n",
    "              f'{scaler}__ngram_range': ngram_list}\n",
    "    return pipe_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [200, 300, 400],\n",
       " 'cvec__min_df': [2, 3],\n",
       " 'cvec__max_df': [0.9, 0.95],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_params('cvec', [200,300,400], [2,3], [.9, .95], [(1,1), (1,2)]) #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go - now I can enter a scaler and 4 lists and get back a parameters dictionary. I'm going to put both of these functions into a python file so I can call them in regularly without clogging up my notebook. I can also add other things the the python file as I go along if it proves helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_utils as utils #import my python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxfeats = [10_000, 20_000] #try different volume of features\n",
    "mindf = [3, 5] #minimum word frequency to be included in the model\n",
    "maxdf = [.9, .95] #cutoff for words more frequent than percentage (float) threshhold\n",
    "ngrams = [(1,1),(1,2)] #range of combinations of words to try (minimum, maximum)\n",
    "scaler = 'cvec'\n",
    "classifier = 'nb'\n",
    "\n",
    "#pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=4,        #use 4 cores to process faster\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be a good place to add another function to my .py file - one that gives me the best parameters, scores training and test data, and creates a confusion matrix for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, X_train, y_train, X_test, y_test):\n",
    "    print(f'The best parameters are: {model.best_params_}')\n",
    "    print(f'The best training score was: {model.best_score_}')\n",
    "    print(f'The test score is: {model.score(X_test, y_test)}')\n",
    "    preds = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    print('_'*20)\n",
    "    print('Confusion Matrix for Test Set:')\n",
    "    plot_confusion_matrix(model, X_test, y_test, cmap='Blues', values_format='d');\n",
    "    plt.show()\n",
    "    print(f'The Accurracy score is {metrics.accuracy_score(y_test, preds)}')\n",
    "    print(f'The Sensitivity score is {metrics.recall_score(y_test, preds)}')\n",
    "    print(f'The Precision score is {metrics.precision_score(y_test, preds)}')\n",
    "    print('_'*20)\n",
    "    print('Receiver Operating Characteristic (ROC) curve:')\n",
    "    metrics.plot_roc_curve(model, X_test, y_test);\n",
    "    plt.show()\n",
    "    return 'Model scored!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_model(gs, X_train, y_train, X_test, y_test) #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! I'll add that function to my utility file as well.  \n",
    "\n",
    "Let's see how the first grid search scored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is the printout that score_model() provided (except for the graphs):\n",
    "\n",
    "The best parameters are: {'cvec__max_df': 0.9, 'cvec__max_features': 20000, 'cvec__min_df': 5, 'cvec__ngram_range': (1, 2)}  \n",
    "The best training score was: 0.9050761571304051  \n",
    "The test score is: 0.9062372604973502  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown here)  \n",
    "\n",
    "The Accurracy score is 0.9062372604973502  \n",
    "The Sensitivity score is 0.9211369095276221  \n",
    "The Precision score is 0.8974258970358814  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown here)  \n",
    "\n",
    "'Model scored!'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says that my best model used words that appeared in 90% or less of my text, 20,000 features, and words that appeared 5 separate times or more. It also factored in single words and words that appear in pairs. The model scored 90.5% accuracy on the training data and 90.6% accuracy on the test data so no apparent bias or variance issues! The Sensitivity score is a little better than the Precision score, suggesting that my model is a little better at avoiding false negatives than avoiding false positives.  \n",
    "\n",
    "### Model 2\n",
    "\n",
    "I'm going to adjust some of the parameters:  \n",
    "- features - my highest parameter (20k) was the best last time, let's try higher  \n",
    "- mindf - my highest parameter (5) was the best last time, let's try higher  \n",
    "- maxdf - the lower end of my options (.9) was the best last time, lets try lower  \n",
    "- ngrams - the higher ngram counts (1,2) was optimal, let's try other, higher combinations\n",
    "- same scaler (cvec) and classifier (nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxfeats = [20_000, 30_000, 40_000] #try different volume of features\n",
    "mindf = [5, 6, 7] #minimum word frequency to be included in the model\n",
    "maxdf = [.8, .85, .9] #cutoff for words more frequent than percentage (float) threshhold\n",
    "ngrams = [(1,2), (2,3), (2,4)] #range of combinations of words to try (minimum, maximum)\n",
    "scaler = 'cvec'\n",
    "classifier = 'nb'\n",
    "\n",
    "#pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=4,        #use 4 cores to process faster\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() printout:\n",
    "\n",
    "The best parameters are: {'cvec__max_df': 0.8, 'cvec__max_features': 20000, 'cvec__min_df': 5, 'cvec__ngram_range': (1, 2)}  \n",
    "The best training score was: 0.9050761571304051  \n",
    "The test score is: 0.9062372604973502  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown)  \n",
    "\n",
    "The Accurracy score is 0.9062372604973502  \n",
    "The Sensitivity score is 0.9211369095276221  \n",
    "The Precision score is 0.8974258970358814  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown)  \n",
    "\n",
    "'Model scored!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting implications of this second model. The best parameters included frequencies of 80% or lower, which was the lowest possible. I'm starting to think I'm dealing with a LOT of stop words which is why the grid search continues to prefer lower frequency words. My model did not prefer a higher minimum frequency than 5 even though 6 and 7 were also tried. The ngram range also stayed the same despite some higher options being available. Most bizarrely, my scores are pretty much the same all the way through as model one, suggesting none of the changes I attempted had any real impact on model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3  \n",
    "\n",
    "I'm going to try removing some stop words. I have to pause here for a moment and update my set_params function in the .py file to include that hyperparameter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(scaler, max_feat_list, min_df_list, max_df_list, sw_list, ngram_list):\n",
    "    if scaler != 'cvec' and scaler != 'tvec':\n",
    "        return 'Please enter either cvec or tvec as the first item.'\n",
    "    pipe_params = {f'{scaler}__max_features': max_feat_list,\n",
    "              f'{scaler}__min_df': min_df_list,\n",
    "              f'{scaler}__max_df': max_df_list,\n",
    "              f'{scaler}__stop_words': sw_list, #adding stop word list\n",
    "              f'{scaler}__ngram_range': ngram_list}\n",
    "    return pipe_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "#https://stackabuse.com/removing-stop-words-from-strings-in-python/\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopwords.words('english'))  #preview stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxfeats = [15_000, 20_000, 30_000] #try different volume of features\n",
    "mindf = [3, 5] #minimum word frequency to be included in the model\n",
    "maxdf = [.8, .9] #cutoff for words more frequent than percentage (float) threshhold\n",
    "ngrams = [(1,2), (1,3)] #range of combinations of words to try (minimum, maximum)\n",
    "swords = [None, stopwords.words('english')] #try None and a standard stop word list\n",
    "scaler = 'cvec'\n",
    "classifier = 'nb'\n",
    "\n",
    "pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, swords, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=4,        #use 4 cores to process faster\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() output:\n",
    "\n",
    "The best parameters are: {'cvec__max_df': 0.8, 'cvec__max_features': 15000, 'cvec__min_df': 5, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': {list of stop words}  \n",
    "The test score is: 0.9076640847941296  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown)\n",
    "\n",
    "The Accurracy score is 0.9076640847941296  \n",
    "The Sensitivity score is 0.9283426741393115  \n",
    "The Precision score is 0.8943308908600077  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown)  \n",
    "\n",
    "'Model scored!'\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few takewaways from model 3; the best parameters still included words under 80% frequencey, even with stop words removed. However, the max features hyperparameter of 15k was preferred to 20k which scored best in the two prior models. Minimum frequency was still best at 5, the ngram range was still (1,2), and as we might expect, using the stop word list was preferred to leaving them out. Notwithstanding all of that, my test accuracy score barely improved (about .001). I'm going to switch into the TF-IDF method and see if that makes a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4  \n",
    "\n",
    "This will be my first model using the TF-IDF vectorizer which will score word importance as a ratio. I'll just keep all the other parameters the same for comparison purposes, but I am going to save the stopwords.words('english') list as a variable. I'm also going to up my processing speed by adding a 5th core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_slist = stopwords.words('english')\n",
    "maxfeats = [15_000, 20_000, 30_000] #try different volume of features\n",
    "mindf = [3, 5] #minimum word frequency to be included in the model\n",
    "maxdf = [.8, .9] #cutoff for words more frequent than percentage (float) threshhold\n",
    "ngrams = [(1,2), (1,3)] #range of combinations of words to try (minimum, maximum)\n",
    "swords = [None, nltk_slist] #try None and a standard stop word list\n",
    "scaler = 'tvec' #CHANGING SCALER <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "classifier = 'nb'\n",
    "\n",
    "pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, swords, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=5,        #UPPING TO 5 CORES <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() output:  \n",
    "\n",
    "The best parameters are: {'tvec__max_df': 0.8, 'tvec__max_features': 15000, 'tvec__min_df': 5, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': stop word list}  \n",
    "The best training score was: 0.8999122595621148  \n",
    "The test score is: 0.8982878108438647  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown)\n",
    "\n",
    "The Accurracy score is 0.8982878108438647  \n",
    "The Sensitivity score is 0.9099279423538831  \n",
    "The Precision score is 0.8924224577934825  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown)  \n",
    "\n",
    "'Model scored!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. It looks like the best tvec model opted for all the same features than my previous cvec model did, but resulted in lower scores across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5  \n",
    "\n",
    "I'm going to revert to the more accurate cvec scaler for my next model. As touched upon previously, the best model seems to always pick the lowest max data frequency percentage when given a range. I'm going to try some even lower ranges and see if a)the lowest range is selected again and b)this improves accuracy in any substantial way. Also, since I added stop words in Model 3, the grid search has selected 15,000 features as ideal as opposed to 20k or 30k. I'm going to try some lower feature options and see if that makes a difference. Finally, I'm going to add some different minimum frequency options - \"5\" has been the most popular so I'll offer 4 and 6 as alternatives.  \n",
    "\n",
    "I'm also going to stop testing \"None\" for stop words. Clearly they're helping, there's no reason to keep trying models without a stop word list going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_slist = stopwords.words('english')\n",
    "maxfeats = [10_000, 12_000, 15_000, 20_000] #try different volume of features\n",
    "mindf = [4, 5, 6] #minimum word frequency to be included in the model\n",
    "maxdf = [.5, .6, .7, .8] #cutoff for words more frequent than percentage (float) threshhold\n",
    "ngrams = [(1,2), (1,3)] #range of combinations of words to try (minimum, maximum)\n",
    "swords = [nltk_slist] #try None and a standard stop word list\n",
    "scaler = 'cvec' #back to cvec\n",
    "classifier = 'nb'\n",
    "\n",
    "pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, swords, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=5,        #using 5 cores to process\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() output:  \n",
    "\n",
    "The best parameters are: {'cvec__max_df': 0.5, 'cvec__max_features': 20000, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': stop word list}  \n",
    "The best training score was: 0.907522386392176  \n",
    "The test score is: 0.9080717488789237  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown)  \n",
    "\n",
    "The Accurracy score is 0.9080717488789237  \n",
    "The Sensitivity score is 0.9267413931144916  \n",
    "The Precision score is 0.8962446767324816  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown)  \n",
    "\n",
    "'Model scored!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some takeaways here: again, the lowest frequency was selected (0.5); max features went back up to 20k rather than 15k. Minimum data frequency adjusted to 4 instead of 5 when given the opportunity. The ideal ngram range stayed the same at (1,2). Accuracy did not improve significantly over my most accurate prior model (Model 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant Words  \n",
    "\n",
    "I'm going to pause modeling at this point to see which words my model (Model 5) finds to be most commonly occurring for each subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/62096337/how-do-you-find-which-words-a-trained-naive-bayes-classifier-uses-to-make-decisi\n",
    "#https://stackoverflow.com/questions/24375911/how-to-print-estimated-coefficients-after-a-gridsearchcv-fit-a-model-sgdregr\n",
    "#https://stackoverflow.com/questions/43856280/return-coefficients-from-pipeline-object-in-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Code below commented out because making the graph would require running the grid search. Image was saved and appears in markdown (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_f = gs.best_estimator_.named_steps['cvec']\n",
    "#class_f = gs.best_estimator_.named_steps['nb']\n",
    "#referred to lesson 5.05\n",
    "#XT_df = pd.DataFrame(scale_f.fit_transform(X_train).todense(), columns = scale_f.get_feature_names())\n",
    "#plt.figure(figsize=(12,5))\n",
    "#plt.title('Most Frequent Words in X_train Data Set After Stop Words Removed', size=25)\n",
    "#plt.xlabel('Number of Uses (out of 14,717 posts in training set)', size=20)\n",
    "\n",
    "#XT_df.sum().sort_values(ascending=False).head(10).plot(kind='barh')\n",
    "#plt.savefig('./images/m5_word_frequency', dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model 5 - Most Frequent Words](./images/m5_word_frequency.png)\n",
    "\n",
    "Some keys about this distribution:  \n",
    "- 'xbox' is the most frequent word, appearing in nearly 12,000 posts. This is especially impressive since the sample is a little over 14,000 posts, of which about half are from the playstation subreddit. So while we might expect the xbox to be referenced regularly in the 7,000 xbox subreddit samples, it seems that close to 5,000 playstaion posts also reference it.  \n",
    "-  'ps4' appears in less than half of the posts overall, so xbox subredditors seem to not be as regular with referencing their rival as playstation subredditors are\n",
    "- aside from the system references, the other words could probably be considered stop words for a gaming subreddit (know, like, account, play, get, one, games, game). I'm going to try a new stopword list that includes those 8 and see how we do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_slist = stopwords.words('english')\n",
    "nltk_slist.append(['know', 'like', 'account', 'play', 'get', 'one', 'games', 'game']) #<<<<< adding stop words\n",
    "maxfeats = [12_000, 15_000, 20_000] #try different volume of features\n",
    "mindf = [4, 5] #minimum word frequency to be included in the model\n",
    "maxdf = [.5, .6, .7, .8] #cutoff for words more frequent than percentage (float) threshhold\n",
    "ngrams = [(1,2), (1,3)] #range of combinations of words to try (minimum, maximum)\n",
    "swords = [stopwords.words('english'), nltk_slist] #<<<<<<<<<<<<< trying standard and edited stop word lists\n",
    "scaler = 'cvec' #back to cvec\n",
    "classifier = 'nb'\n",
    "\n",
    "pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, swords, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=5,        #using 5 cores to process\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() output:  \n",
    "\n",
    "The best parameters are: {'cvec__max_df': 0.5, 'cvec__max_features': 20000, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': (nltk list)  \n",
    "The best training score was: 0.907522386392176  \n",
    "The test score is: 0.9080717488789237  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown)  \n",
    "\n",
    "The Accurracy score is 0.9080717488789237  \n",
    "The Sensitivity score is 0.9267413931144916  \n",
    "The Precision score is 0.8962446767324816  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown)  \n",
    "\n",
    "'Model scored!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same maxdf, max features, mindf, and ngram range were all selected as ideal. More interestingly, my \"edited\" stop words list was *NOT* selected for the best model. So removing those common words was not helpful. Since this model chose all the same parameters that my last model did (Model 6), it has the same accuracy scores. Perhaps this should not be surprising, given that max df is 50%. Any words that appear in more than 50% of the posts aren't being included anyways, and that hyperparameter is probably overshadowing any stop word adjustments I make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient Considerations  \n",
    "\n",
    "I'm going to try to pull out the largest coefficients from this last model.  \n",
    "\n",
    "Again - the code will be commented out because running it would require running the grid search. My results will be put into markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_f = gs.best_estimator_.named_steps['cvec']\n",
    "#class_f = gs.best_estimator_.named_steps['nb']\n",
    "\n",
    "#coef_df = pd.DataFrame(class_f.coef_, columns = scale_f.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_df.sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 25 Coefficients:\n",
    "\n",
    "|  ngram(1,2)     |     coef |\n",
    "|:----------------|---------:|\n",
    "| made xbox       | -12.8359 |\n",
    "| better pc       | -12.8359 |\n",
    "| gp ultimate     | -12.8359 |\n",
    "| problem posting | -12.8359 |\n",
    "| grammar         | -12.8359 |\n",
    "| beta xbox       | -12.8359 |\n",
    "| beta support    | -12.8359 |\n",
    "| beta pc         | -12.8359 |\n",
    "| beta app        | -12.8359 |\n",
    "| best xbox       | -12.8359 |\n",
    "| problem headset | -12.8359 |\n",
    "| green screen    | -12.8359 |\n",
    "| use series      | -12.8359 |\n",
    "| use gamepass    | -12.8359 |\n",
    "| use use         | -12.8359 |\n",
    "| group post      | -12.8359 |\n",
    "| use xcloud      | -12.8359 |\n",
    "| used 360        | -12.8359 |\n",
    "| dating          | -12.8359 |\n",
    "| price series    | -12.8359 |\n",
    "| guys one        | -12.8359 |\n",
    "| gwg             | -12.8359 |\n",
    "| prestige        | -12.8359 |\n",
    "| hall            | -12.8359 |\n",
    "| hall fame       | -12.8359 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of coefficients appears to run from around -4 to -12, and there are no positive coefficients. The list above shows the top 25 although they all seem to be of the same magnitude. This is odd. I'm going to see if I can isolate the best set of parameters from my grid search in the next model, and then I want to load those into a new naive bayes model (outside of a pipeline) so that it's easier to evaluate the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7  \n",
    "\n",
    "#### Enter the Lemmatizer\n",
    "\n",
    "An important aspect that I have yet to attempt in my modeling is the lemmatizer option. This would reduce words to their root (i.e. \"game\" and \"games\" both reduce to \"game\") and might help make my model more accurate. I will lemmatize X_train and X_test and then run them through the model to see what the affect might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lesson 5.03 \n",
    "#https://stackoverflow.com/questions/40902430/lemmatization-inside-array-using-nltk-python\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #create tokenizer to remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens = [tokenizer.tokenize(x) for x in X_train]\n",
    "X_test_tokens = [tokenizer.tokenize(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem = []\n",
    "for item in X_train_tokens:\n",
    "    X_lem = []\n",
    "    for word in item:\n",
    "        X_lem.append(lemmatizer.lemmatize(word))\n",
    "    X_train_lem.append(' '.join(X_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lem = []\n",
    "for item in X_test_tokens:\n",
    "    X_lem = []\n",
    "    for word in item:\n",
    "        X_lem.append(lemmatizer.lemmatize(word))\n",
    "    X_test_lem.append(' '.join(X_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed:   47.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'cvec__max_df': 0.5, 'cvec__max_features': 15000, 'cvec__min_df': 5, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]}\n",
      "The best training score was: 0.9069791158829352\n",
      "The test score is: 0.9060334284549532\n",
      "____________________\n",
      "Confusion Matrix for Test Set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accurracy score is 0.9060334284549532\n",
      "The Sensitivity score is 0.9271417133706965\n",
      "The Precision score is 0.892485549132948\n",
      "____________________\n",
      "Receiver Operating Characteristic (ROC) curve:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Model scored!'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk_slist = stopwords.words('english') <<<<<<<<<<<<<<<< NOT USING THIS LIST, MAKES NO DIFFERENCE\n",
    "#nltk_slist.append(['know', 'like', 'account', 'play', 'get', 'one', 'games', 'game'])\n",
    "maxfeats = [15_000, 20_000, 30_000] #try different volume of features\n",
    "mindf = [4, 5] #minimum word frequency to be included in the model\n",
    "maxdf = [.2, .4, .5, .7] #cutoff for words more frequent than percentage (float) threshhold << testing .1-.5\n",
    "ngrams = [(1,2)] #range of combinations of words to try (minimum, maximum) <<<<<<<< only (1,2)\n",
    "swords = [stopwords.words('english')] #<<<<<<<<<<<<< only standard stop words\n",
    "scaler = 'cvec' #continuing with cvec\n",
    "classifier = 'nb'\n",
    "\n",
    "pipe = utils.pipemaker(scaler, classifier)\n",
    "#params = utils.set_params(scaler, maxfeats, mindf, maxdf, swords, ngrams)\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                 # n_jobs=6,        #<<<<<<<<<<<<<<< adding a 6th core to process\n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train_lem, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train_lem, y_train, X_test_lem, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() output:  \n",
    "\n",
    "The best parameters are: {'cvec__max_df': 0.5, 'cvec__max_features': 15000, 'cvec__min_df': 5, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': (stop word list)}  \n",
    "The best training score was: 0.9069791158829352  \n",
    "The test score is: 0.9060334284549532  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown here)  \n",
    "\n",
    "The Accurracy score is 0.9060334284549532  \n",
    "The Sensitivity score is 0.9271417133706965  \n",
    "The Precision score is 0.892485549132948  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown here)  \n",
    "\n",
    "'Model scored!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like accuracy scores are slightly worse that prior models so the lemmatizer did not improve my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8  \n",
    "\n",
    "I'm going to implement the Porter Stemmer to see if that helps at all. My code to make the lemmatizer was a little bit clunky so for this attempt I'm going to try to make my own class and then insert it into the tokenizer hyperparameter for my Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/47423854/sklearn-adding-lemmatizer-to-countvectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "class PS_Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = PorterStemmer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.stem(x) for x in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-124-f59a96bdbe42>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-124-f59a96bdbe42>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    n_jobs=6,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "maxfeats = [20_000] #try different volume of features\n",
    "mindf = [4] #minimum word frequency to be included in the model\n",
    "maxdf = [.4, .5,] #cutoff for words more frequent than percentage (float) threshhold << testing .1-.5\n",
    "ngrams = [(1,2)] #range of combinations of words to try (minimum, maximum) <<<<<<<< only (1,2)\n",
    "swords = [stopwords.words('english')] #<<<<<<<<<<<<< only standard stop words\n",
    "scaler = 'cvec' #continuing with cvec\n",
    "classifier = 'nb'\n",
    "\n",
    "pipe = utils.pipemaker(scaler, classifier)\n",
    "\n",
    "#Doing custom params list because my python file function is not built to accept the tokenizer hyperparameter\n",
    "\n",
    "params = {'cvec__max_features': maxfeats,\n",
    "          'cvec__min_df': mindf,\n",
    "          'cvec__max_df': maxdf,\n",
    "          'cvec__stop_words':swords,\n",
    "          'cvec__tokenizer':[PS_Tokenizer()],\n",
    "          'cvec__ngram_range': [(1, 2)]}\n",
    "\n",
    "#gs = GridSearchCV(pipe, params, #load hyperparameters\n",
    "                  #n_jobs=6,        \n",
    "                  #cv=5, verbose=1) #using 5 folds and lower verbose to limit messages returned\n",
    "\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "#utils.score_model(gs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_model() output:  \n",
    "The best parameters are: {'cvec__max_df': 0.5, 'cvec__max_features': 20000, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': (stop word list), 'cvec__tokenizer': <__main__.PS_Tokenizer object at 0x0000022312297E80>}  \n",
    "The best training score was: 0.9058911898535952  \n",
    "The test score is: 0.9046066041581736  \n",
    "____________________\n",
    "Confusion Matrix for Test Set: (not shown here)  \n",
    "\n",
    "The Accurracy score is 0.9046066041581736  \n",
    "The Sensitivity score is 0.9295436349079264  \n",
    "The Precision score is 0.8882938026013772  \n",
    "____________________\n",
    "Receiver Operating Characteristic (ROC) curve: (not shown here)  \n",
    "\n",
    "'Model scored!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pleased that I was able to create my new PS_Tokenizer class in order to run this model, however the accuracy score in output was not an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9  \n",
    "At this point I'm confident that I've isolated the best Naive Bayes parameters. I'm going to run that model outside of my pipeline functions so that I can more easily examine the coefficients and other aspects of it.  \n",
    "\n",
    "As a recap- these seem to consistently be the hyperparameters that my grid searches recommend:  \n",
    "- maxdf = .4\n",
    "- maxfeatures = 20_000\n",
    "- mindf = 4\n",
    "- ngram range = (1,2)\n",
    "- stopwords = base nltk stop word list\n",
    "- scaler = cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best training score was: 0.9414282802201536\n",
      "The test score is: 0.9080717488789237\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(max_features=20_000,\n",
    "                       min_df=4, \n",
    "                       max_df = .4,\n",
    "                       ngram_range=(1,2),\n",
    "                       stop_words=stopwords.words('english'))\n",
    "X_train_c = cvec.fit_transform(X_train)\n",
    "X_test_c = cvec.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_c, y_train)\n",
    "\n",
    "print(f'The best training score was: {nb.score(X_train_c, y_train)}')\n",
    "print(f'The test score is: {nb.score(X_test_c, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! Slight overfit but in general a solid 94% accuracy on the training data and about 91% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accurracy score is 0.9080717488789237\n",
      "The Sensitivity score is 0.9267413931144916\n",
      "The Precision score is 0.8962446767324816\n"
     ]
    }
   ],
   "source": [
    "preds = nb.predict(X_test_c)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "plot_confusion_matrix(nb, X_test_c, y_test, cmap='gist_earth', values_format='d');\n",
    "plt.show()\n",
    "print(f'The Accurracy score is {metrics.accuracy_score(y_test, preds)}')\n",
    "print(f'The Sensitivity score is {metrics.recall_score(y_test, preds)}')\n",
    "print(f'The Precision score is {metrics.precision_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the earlier models we see that Sensitivity is optimized in this model compared to Precision. This means the model is slightly better at avoiding False Negatives than avoiding False Positives. To restate that in context of our data, it's slightly more likely that a post classified as \"not-Playstation\", i.e. Xbox, is correct than it is that something we classified as \"Playstation\" is truly Playstation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>made xbox</th>\n",
       "      <td>-12.835950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better pc</th>\n",
       "      <td>-12.835950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp ultimate</th>\n",
       "      <td>-12.835950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem posting</th>\n",
       "      <td>-12.835950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>-12.835950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playstation</th>\n",
       "      <td>-4.912964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>-4.818642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps5</th>\n",
       "      <td>-4.761612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>games</th>\n",
       "      <td>-4.685771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps4</th>\n",
       "      <td>-4.380845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "made xbox       -12.835950\n",
       "better pc       -12.835950\n",
       "gp ultimate     -12.835950\n",
       "problem posting -12.835950\n",
       "grammar         -12.835950\n",
       "...                    ...\n",
       "playstation      -4.912964\n",
       "game             -4.818642\n",
       "ps5              -4.761612\n",
       "games            -4.685771\n",
       "ps4              -4.380845\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(nb.coef_, columns = cvec.get_feature_names())\n",
    "coef_df.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, it appears all of my 20_000 coefficients were negative, meaning the inverse relationships to our target 1 (Playstation) were stronger than any positive options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.449655    2418\n",
       "-11.226512    2379\n",
       "-11.737338    2166\n",
       "-11.044190    1856\n",
       "-12.142803    1432\n",
       "-12.835950    1413\n",
       "-10.890040    1290\n",
       "-10.756508     925\n",
       "-10.638725     704\n",
       "-10.533365     554\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.T[0].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 10 most frequently recurring coefficients - some appear over 2_000 times! Clearly a lot of these words appeared not only the same proportion of times but also nearly exclusively in the Xbox (0) subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>made xbox</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better pc</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp ultimate</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem posting</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta xbox</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta support</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta pc</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta app</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best xbox</th>\n",
       "      <td>-12.83595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "made xbox       -12.83595\n",
       "better pc       -12.83595\n",
       "gp ultimate     -12.83595\n",
       "problem posting -12.83595\n",
       "grammar         -12.83595\n",
       "beta xbox       -12.83595\n",
       "beta support    -12.83595\n",
       "beta pc         -12.83595\n",
       "beta app        -12.83595\n",
       "best xbox       -12.83595"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.T.sort_values(by=0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1432 coefficients tied for strongest coefficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 10  \n",
    "#### Random Forest  \n",
    "(NOTES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
